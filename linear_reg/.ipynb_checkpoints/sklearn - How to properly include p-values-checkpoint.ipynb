{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to (properly) include p-values with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For these lessons we will need NumPy, pandas, matplotlib and seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# and of course the actual regression (machine learning) module\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a .csv in the same folder\n",
    "data = pd.read_csv('1.02. Multiple linear regression.csv')\n",
    "\n",
    "# Let's explore the top 5 rows of the df\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method gives us very nice descriptive statistics. We don't need this for now, but will later on!\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two independent variables: 'SAT' and 'Rand 1,2,3'\n",
    "x = data[['SAT','Rand 1,2,3']]\n",
    "\n",
    "# and a single depended variable: 'GPA'\n",
    "y = data['GPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to (properly) include p-values in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the p-values are obtained through certain statistics, we need the 'stat' module from scipy.stats\n",
    "import scipy.stats as stat\n",
    "\n",
    "# Since we are using an object oriented language such as Python, we can simply define our own \n",
    "# LinearRegression class (the same one from sklearn)\n",
    "# By typing the code below we will ovewrite a part of the class with one that includes p-values\n",
    "# Here's the full source code of the ORIGINAL class: https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362\n",
    "\n",
    "\n",
    "class LinearRegression(linear_model.LinearRegression):\n",
    "    \"\"\"\n",
    "    LinearRegression class after sklearn's, but calculate t-statistics\n",
    "    and p-values for model coefficients (betas).\n",
    "    Additional attributes available after .fit()\n",
    "    are `t` and `p` which are of the shape (y.shape[1], X.shape[1])\n",
    "    which is (n_features, n_coefs)\n",
    "    This class sets the intercept to 0 by default, since usually we include it\n",
    "    in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    # nothing changes in __init__\n",
    "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True,\n",
    "                 n_jobs=1):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, n_jobs=1):\n",
    "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
    "        \n",
    "        # Calculate SSE (sum of squared errors)\n",
    "        # and SE (standard error)\n",
    "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "\n",
    "        # compute the t-statistic for each feature\n",
    "        self.t = self.coef_ / se\n",
    "        # find the p-value for each feature\n",
    "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we create the regression everything is the same\n",
    "reg_with_pvalues = LinearRegression()\n",
    "reg_with_pvalues.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference is that we can check what's contained in the local variable 'p' in an instance of the LinearRegression() class\n",
    "reg_with_pvalues.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new data frame with the names of the features\n",
    "reg_summary = pd.DataFrame([['SAT'],['Rand 1,2,3']],columns =['Features'])\n",
    "# Then we create and fill a second column, called 'Coefficients' with the coefficients of the regression\n",
    "reg_summary['Coefficients'] = reg_with_pvalues.coef_\n",
    "# Finally, we add the p-values we just calculated\n",
    "reg_summary['p-values'] = reg_with_pvalues.p.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This result is identical to the one from StatsModels\n",
    "reg_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
